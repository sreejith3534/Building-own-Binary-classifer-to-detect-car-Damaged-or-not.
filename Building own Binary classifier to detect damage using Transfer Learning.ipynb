{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "car_damage_modified_14/02/2019.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreejith3534/Building-own-Binary-classifer-to-detect-car-Damaged-or-not./blob/master/Building%20own%20Binary%20classifier%20to%20detect%20damage%20using%20Transfer%20Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WgmlBWHD0dS7",
        "colab_type": "code",
        "outputId": "201af294-2317-490a-955f-f371967ade3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D54bvBMJ0h45",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "from IPython.display import Image, display, clear_output\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "%matplotlib inline\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "sns.set_style('whitegrid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vz-3gqQp0jRw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_width = 256\n",
        "img_height = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VAuDmksu5oRI",
        "colab_type": "code",
        "outputId": "8bb629f2-5225-46f5-959b-2cc78758ac78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.regularizers import l2,l1\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint, History\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "pn1bBLT68eBq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(3, 256, 256), pooling=max, classes=1000)\n",
        "model.save('/content/drive/My Drive/car_data/vgg_16.h5') ## save it so as to save time  in loading again"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9Y0bUNB6eC8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_vgg16(weights_path='/content/drive/My Drive/car_data/vgg_16.h5'):\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1,1),input_shape=(3, img_width, img_height)))\n",
        "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "    if weights_path:\n",
        "        model.load_weights(weights_path)\n",
        "        print('VGG16 Model with partial weights loaded.')\n",
        "    else:\n",
        "        print('VGG16 Model with no weights Loaded.')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZuM3aV2pCmhS",
        "colab_type": "code",
        "outputId": "7218b2c5-67d2-4487-cf39-190eba50a7da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "load_vgg16()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "VGG16 Model with partial weights loaded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7ff5ebc604a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "dQBgbqJvCFhp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "location = '/content/drive/My Drive/car_data/data1a'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NvhGGUY3CFgx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_dir = location+'/training'\n",
        "validation_data_dir = location+'/validation'\n",
        "train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
        "nb_train_samples = sum(train_samples)\n",
        "validation_samples = [len(os.listdir(validation_data_dir+'/'+i)) for i in sorted(os.listdir(validation_data_dir))]\n",
        "train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
        "nb_validation_samples = sum(validation_samples)\n",
        "nb_epoch = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzUjPTt-BtAm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_bottleneck_features(location):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)  \n",
        "    \n",
        "    model = load_vgg16()\n",
        "    \n",
        "    generator = datagen.flow_from_directory('/content/drive/My Drive/car_data/data1a/training',\n",
        "                                            target_size=(img_width, img_height),\n",
        "                                            batch_size=16, \n",
        "                                            class_mode=None, \n",
        "                                            shuffle=False) \n",
        "#     print(generator)\n",
        "    \n",
        "    bottleneck_features_train = model.predict_generator(generator, 115)\n",
        "    np.save(open(location+'/bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
        "    \n",
        "    # repeat with the validation data\n",
        "    generator = datagen.flow_from_directory('/content/drive/My Drive/car_data/data1a/validation',\n",
        "                                           target_size=(img_width, img_height),\n",
        "                                           batch_size=16,\n",
        "                                           class_mode=None,\n",
        "                                           shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(generator, 29)\n",
        "    np.save(open(location+'/bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zkiTr1n8BtDd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_bottleneck_features(location) ### dont rerun as already numpy array will be created first"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJkGDANUTRC8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top_model_weights_path = '/content/drive/My Drive/car_data/data1a/new_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_7osihdoBtGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_binary_model():\n",
        "\n",
        "    train_data = np.load('/content/drive/My Drive/car_data/data1a/bottleneck_features_train.npy')\n",
        "    train_labels = np.array([0] * train_samples[0] + \n",
        "                            [1] * train_samples[1])\n",
        "    validation_data = np.load('/content/drive/My Drive/car_data/data1a/bottleneck_features_validation.npy')\n",
        "    validation_labels = np.array([0] * validation_samples[0] + \n",
        "                                 [1] * validation_samples[1])\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:])) # 512, 4, 4\n",
        "    model.add(Dense(256, activation = 'relu', W_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5)) \n",
        "    model.add(Dense(1, activation = 'sigmoid')) \n",
        "    model.compile(optimizers.adam(lr=0.0001),\n",
        "              loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    \n",
        "    checkpoint = ModelCheckpoint(top_model_weights_path, monitor='val_acc', \n",
        "                                 verbose=1, save_best_only=True, save_weights_only=True, mode='auto')\n",
        "\n",
        "    fit = model.fit(train_data, train_labels,\n",
        "              nb_epoch=nb_epoch, batch_size=16,\n",
        "              validation_data=(validation_data, validation_labels),\n",
        "              callbacks=[checkpoint])\n",
        "    \n",
        "#     with open(location+'/top_history.txt', 'wb') as f:\n",
        "#         json.dump(fit.history, f)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3frUa_1RSioR",
        "colab_type": "code",
        "outputId": "b00c5f0a-7683-47ff-81d8-d080f4e07ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "cell_type": "code",
      "source": [
        "# train_binary_model()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1840 samples, validate on 460 samples\n",
            "Epoch 1/10\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 3.4765 - acc: 0.8120 - val_loss: 2.1773 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.90870, saving model to /content/drive/My Drive/car_data/data1a/new_model.h5\n",
            "Epoch 2/10\n",
            "1840/1840 [==============================] - 2s 1ms/step - loss: 1.8217 - acc: 0.8913 - val_loss: 1.4955 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.90870\n",
            "Epoch 3/10\n",
            "1840/1840 [==============================] - 2s 1ms/step - loss: 1.2952 - acc: 0.9223 - val_loss: 1.1645 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.90870\n",
            "Epoch 4/10\n",
            "1840/1840 [==============================] - 2s 1ms/step - loss: 0.9991 - acc: 0.9386 - val_loss: 0.9383 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.90870 to 0.92391, saving model to /content/drive/My Drive/car_data/data1a/new_model.h5\n",
            "Epoch 5/10\n",
            "1840/1840 [==============================] - 2s 1ms/step - loss: 0.8193 - acc: 0.9435 - val_loss: 0.9049 - val_acc: 0.8848\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.92391\n",
            "Epoch 6/10\n",
            "1840/1840 [==============================] - 2s 1ms/step - loss: 0.6796 - acc: 0.9554 - val_loss: 0.7330 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.92391\n",
            "Epoch 7/10\n",
            "1840/1840 [==============================] - 2s 1ms/step - loss: 0.5636 - acc: 0.9690 - val_loss: 0.6284 - val_acc: 0.9217\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.92391\n",
            "Epoch 8/10\n",
            "1840/1840 [==============================] - 2s 1ms/step - loss: 0.4803 - acc: 0.9728 - val_loss: 0.5597 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.92391\n",
            "Epoch 9/10\n",
            "1840/1840 [==============================] - 2s 1ms/step - loss: 0.4151 - acc: 0.9853 - val_loss: 0.5284 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.92391\n",
            "Epoch 10/10\n",
            "1840/1840 [==============================] - 2s 1ms/step - loss: 0.3849 - acc: 0.9728 - val_loss: 0.4922 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.92391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7ff5a7da6978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "uu5rCDt8Snng",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model = load_vgg16()\n",
        "\n",
        "# # build a classifier model to put on top of the convolutional model\n",
        "# top_model = Sequential()\n",
        "# top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
        "# top_model.add(Dense(256, activation='relu', W_regularizer=l2(0.01)))\n",
        "# top_model.add(Dropout(0.5))\n",
        "# top_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# top_model.load_weights(top_model_weights_path) # load weights_path\n",
        "\n",
        "# # add the model on top of the convolutional base\n",
        "# model.add(top_model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qhUfTDTCVeY8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # len(model.layers)\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNV7bYGuU3Kp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def finetune_binary_model():\n",
        "    model = load_vgg16()\n",
        "\n",
        "    # build a classifier model to put on top of the convolutional model\n",
        "    top_model = Sequential()\n",
        "    top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
        "    top_model.add(Dense(256, activation='relu', W_regularizer=l2(0.01)))\n",
        "    top_model.add(Dropout(0.5))\n",
        "    top_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    top_model.load_weights(top_model_weights_path) # load weights_path\n",
        "\n",
        "    # add the model on top of the convolutional base\n",
        "    model.add(top_model)\n",
        "    \n",
        "    for layer in model.layers[:25]:\n",
        "        layer.trainable=False\n",
        "\n",
        "    # compile the model with a adam optimizer \n",
        "    # and a very slow learning rate\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                 optimizer = optimizers.adam(lr=0.00001), # reduced learning rate by 1/10\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # prepare data augmentation configuration\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                       rotation_range=40,\n",
        "                                       width_shift_range=0.2,\n",
        "                                       height_shift_range=0.2,\n",
        "                                       shear_range=0.2,\n",
        "                                       zoom_range=0.2,\n",
        "                                       horizontal_flip=True,\n",
        "                                       fill_mode='nearest')\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator= train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                     target_size=(img_height, img_width),\n",
        "                                                     batch_size=8,\n",
        "                                                     class_mode='binary')\n",
        "\n",
        "    validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                           target_size=(img_height, img_width),\n",
        "                                                           batch_size=8,\n",
        "                                                           class_mode='binary')\n",
        "    \n",
        "    \n",
        "    checkpoint = ModelCheckpoint(fine_tuned_model_path, monitor='val_acc', \n",
        "                                 verbose=1, save_best_only=True, \n",
        "                                 save_weights_only=False, mode='auto')\n",
        "    # fine-tune the model\n",
        "    fit = model.fit_generator(train_generator,\n",
        "                              samples_per_epoch=nb_train_samples,\n",
        "                              nb_epoch=nb_epoch,\n",
        "                              validation_data=validation_generator,\n",
        "                              nb_val_samples=nb_validation_samples,\n",
        "                              verbose=1,\n",
        "                              callbacks=[checkpoint])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f02x1IkkW4ue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fine_tuned_model_path = '/content/drive/My Drive/car_data/data1a/ft_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fPdbzf62WqL1",
        "colab_type": "code",
        "outputId": "d5ead668-dc66-463b-f0c3-d9323fd14a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1142
        }
      },
      "cell_type": "code",
      "source": [
        "ft_model = finetune_binary_model()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "VGG16 Model with partial weights loaded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 1840 images belonging to 2 classes.\n",
            "Found 460 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., verbose=1, callbacks=[<keras.ca..., steps_per_epoch=230, epochs=10, validation_steps=460)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "230/230 [==============================] - 129s 560ms/step - loss: 1.0807 - acc: 0.8190 - val_loss: 0.8138 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.92223, saving model to /content/drive/My Drive/car_data/data1a/ft_model.h5\n",
            "Epoch 2/10\n",
            "230/230 [==============================] - 125s 544ms/step - loss: 0.9124 - acc: 0.8549 - val_loss: 0.8020 - val_acc: 0.8909\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.92223\n",
            "Epoch 3/10\n",
            "230/230 [==============================] - 125s 543ms/step - loss: 0.8361 - acc: 0.8788 - val_loss: 0.7452 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.92223\n",
            "Epoch 4/10\n",
            "230/230 [==============================] - 125s 543ms/step - loss: 0.7844 - acc: 0.8957 - val_loss: 0.6789 - val_acc: 0.9353\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.92223 to 0.93531, saving model to /content/drive/My Drive/car_data/data1a/ft_model.h5\n",
            "Epoch 5/10\n",
            "230/230 [==============================] - 125s 544ms/step - loss: 0.7389 - acc: 0.8989 - val_loss: 0.6759 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.93531\n",
            "Epoch 6/10\n",
            "230/230 [==============================] - 125s 543ms/step - loss: 0.7115 - acc: 0.9027 - val_loss: 0.6315 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.93531\n",
            "Epoch 7/10\n",
            "230/230 [==============================] - 125s 544ms/step - loss: 0.6723 - acc: 0.9125 - val_loss: 0.6755 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.93531\n",
            "Epoch 8/10\n",
            "230/230 [==============================] - 125s 542ms/step - loss: 0.6638 - acc: 0.9163 - val_loss: 0.6606 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.93531\n",
            "Epoch 9/10\n",
            "230/230 [==============================] - 125s 542ms/step - loss: 0.6276 - acc: 0.9217 - val_loss: 0.5898 - val_acc: 0.9285\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.93531\n",
            "Epoch 10/10\n",
            "230/230 [==============================] - 125s 541ms/step - loss: 0.5996 - acc: 0.9272 - val_loss: 0.6868 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.93531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GaVs1BcdXsRw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ft_model_1 = load_model('/content/drive/My Drive/car_data/data1a/ft_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mOM8Pdg9XM5r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def car_categories_gate(image_path, model):\n",
        "    urllib.request.urlretrieve(image_path, 'save.jpg') # or other way to upload image\n",
        "    img = load_img('save.jpg', target_size=(256, 256)) # this is a PIL image \n",
        "    x = img_to_array(img) # this is a Numpy array with shape (3, 256, 256)\n",
        "    x = x.reshape((1,) + x.shape)/255 # this is a Numpy array with shape (1, 3, 256, 256)\n",
        "    pred = model.predict(x)\n",
        "    print(\"Please wait system busy finding if damage exists?\")\n",
        "    print(pred)\n",
        "    if pred[0][0] <=.5:\n",
        "\n",
        "        print(\"Validation complete - proceed to location and severity determination\")\n",
        "    else:\n",
        "        print(\"Are you sure that your car is damaged? Please submit another picture of the damage.\")\n",
        "        print(\"Alternate: go with some other pics of different angle/view and check\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GeqYA9gMXM8j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fb32e668-ee55-4f67-cfbf-0e65e3c978f2"
      },
      "cell_type": "code",
      "source": [
        "car_categories_gate('https://www.copart.co.uk/content/uk/en/landing-page/accident-damaged-classics.jpg',ft_model_1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please wait system busy finding if damage exists?\n",
            "[[0.9481191]]\n",
            "Are you sure that your car is damaged? Please submit another picture of the damage.\n",
            "Alternate: go with some other pics of different angle/view and check\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SMAdeAqRbSNI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LEDon494bSL0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sizhso2UbSJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLvBO3h8a25x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EjJIPvkxreKi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}