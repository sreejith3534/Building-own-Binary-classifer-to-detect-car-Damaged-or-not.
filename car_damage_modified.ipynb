{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "WgmlBWHD0dS7",
    "outputId": "201af294-2317-490a-955f-f371967ade3b"
   },
   "outputs": [],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive   ### if you are using colab then use this this and store data in your drive.\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D54bvBMJ0h45"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from IPython.display import Image, display, clear_output\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vz-3gqQp0jRw"
   },
   "outputs": [],
   "source": [
    "img_width = 256\n",
    "img_height = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VAuDmksu5oRI",
    "outputId": "8bb629f2-5225-46f5-959b-2cc78758ac78"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.regularizers import l2,l1\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pn1bBLT68eBq"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(3, 256, 256), pooling=max, classes=1000)\n",
    "model.save('/content/drive/My Drive/car_data/vgg_16.h5') ## save it so as to save time  in loading again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9Y0bUNB6eC8"
   },
   "outputs": [],
   "source": [
    "def load_vgg16(weights_path='/content/drive/My Drive/car_data/vgg_16.h5'):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3, img_width, img_height)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "        print('VGG16 Model with partial weights loaded.')\n",
    "    else:\n",
    "        print('VGG16 Model with no weights Loaded.')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "ZuM3aV2pCmhS",
    "outputId": "7218b2c5-67d2-4487-cf39-190eba50a7da"
   },
   "outputs": [],
   "source": [
    "load_vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQBgbqJvCFhp"
   },
   "outputs": [],
   "source": [
    "location = 'location of your data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvhGGUY3CFgx"
   },
   "outputs": [],
   "source": [
    "train_data_dir = location+'/training'\n",
    "validation_data_dir = location+'/validation'\n",
    "train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
    "nb_train_samples = sum(train_samples)\n",
    "validation_samples = [len(os.listdir(validation_data_dir+'/'+i)) for i in sorted(os.listdir(validation_data_dir))]\n",
    "train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
    "nb_validation_samples = sum(validation_samples)\n",
    "nb_epoch = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzUjPTt-BtAm"
   },
   "outputs": [],
   "source": [
    "def save_bottleneck_features(location):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)  \n",
    "    \n",
    "    model = load_vgg16()\n",
    "    \n",
    "    generator = datagen.flow_from_directory(train_data_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            batch_size=16, \n",
    "                                            class_mode=None, \n",
    "                                            shuffle=False) \n",
    "#     print(generator)\n",
    "    \n",
    "    bottleneck_features_train = model.predict_generator(generator, 115)\n",
    "    np.save(open(location+'/bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "    \n",
    "    # repeat with the validation data\n",
    "    generator = datagen.flow_from_directory(validation_data_dir,\n",
    "                                           target_size=(img_width, img_height),\n",
    "                                           batch_size=16,\n",
    "                                           class_mode=None,\n",
    "                                           shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(generator, 29)\n",
    "    np.save(open(location+'/bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zkiTr1n8BtDd"
   },
   "outputs": [],
   "source": [
    "save_bottleneck_features(location) ### dont rerun as already numpy array will be created first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CJkGDANUTRC8"
   },
   "outputs": [],
   "source": [
    "bin_model_weights_path = 'location/bin_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7osihdoBtGF"
   },
   "outputs": [],
   "source": [
    "def train_binary_model():\n",
    "\n",
    "    train_data = np.load('location to train npy file')\n",
    "    train_labels = np.array([0] * train_samples[0] + \n",
    "                            [1] * train_samples[1])\n",
    "    validation_data = np.load('location to test npy file')\n",
    "    validation_labels = np.array([0] * validation_samples[0] + \n",
    "                                 [1] * validation_samples[1])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:])) # 512, 4, 4\n",
    "    model.add(Dense(256, activation = 'relu', W_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(1, activation = 'sigmoid')) \n",
    "    model.compile(optimizers.adam(lr=0.0001),\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(bin_model_weights_path, monitor='val_acc', \n",
    "                                 verbose=1, save_best_only=True, save_weights_only=True, mode='auto')\n",
    "\n",
    "    fit = model.fit(train_data, train_labels,\n",
    "              nb_epoch=nb_epoch, batch_size=16,\n",
    "              validation_data=(validation_data, validation_labels),\n",
    "              callbacks=[checkpoint])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "3frUa_1RSioR",
    "outputId": "b00c5f0a-7683-47ff-81d8-d080f4e07ada"
   },
   "outputs": [],
   "source": [
    "train_binary_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNV7bYGuU3Kp"
   },
   "outputs": [],
   "source": [
    "def finetune_binary_model():\n",
    "    model = load_vgg16()\n",
    "\n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu', W_regularizer=l2(0.01)))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    top_model.load_weights(bin_model_weights_path) # load weights_path\n",
    "\n",
    "    # add the model on top of the convolutional base\n",
    "    model.add(top_model)\n",
    "    \n",
    "    for layer in model.layers[:31]:\n",
    "        layer.trainable=False\n",
    "\n",
    "    # compile the model with a adam optimizer \n",
    "    # and a very slow learning rate\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = optimizers.adam(lr=0.00001), # reduced learning rate by 1/10\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                       rotation_range=40,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       shear_range=0.2,\n",
    "                                       zoom_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       fill_mode='nearest')\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator= train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                     target_size=(img_height, img_width),\n",
    "                                                     batch_size=8,\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           batch_size=8,\n",
    "                                                           class_mode='binary')\n",
    "    \n",
    "    \n",
    "    checkpoint = ModelCheckpoint(fine_tuned_model_path, monitor='val_acc', \n",
    "                                 verbose=1, save_best_only=True, \n",
    "                                 save_weights_only=False, mode='auto')\n",
    "    # fine-tune the model\n",
    "    fit = model.fit_generator(train_generator,\n",
    "                              samples_per_epoch=nb_train_samples,\n",
    "                              nb_epoch=nb_epoch,\n",
    "                              validation_data=validation_generator,\n",
    "                              nb_val_samples=nb_validation_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[checkpoint])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f02x1IkkW4ue"
   },
   "outputs": [],
   "source": [
    "fine_tuned_model_path = 'location/ft_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1142
    },
    "colab_type": "code",
    "id": "fPdbzf62WqL1",
    "outputId": "d5ead668-dc66-463b-f0c3-d9323fd14a4f"
   },
   "outputs": [],
   "source": [
    "ft_model = finetune_binary_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaVs1BcdXsRw"
   },
   "outputs": [],
   "source": [
    "ft_model_1 = load_model('location/ft_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOM8Pdg9XM5r"
   },
   "outputs": [],
   "source": [
    "def car_categories_gate(image_path, model):\n",
    "    urllib.request.urlretrieve(image_path, 'save.jpg') # or other way to upload image\n",
    "    img = load_img('save.jpg', target_size=(256, 256)) # this is a PIL image \n",
    "    x = img_to_array(img) # this is a Numpy array with shape (3, 256, 256)\n",
    "    x = x.reshape((1,) + x.shape)/255 # this is a Numpy array with shape (1, 3, 256, 256)\n",
    "    pred = model.predict(x)\n",
    "    print(\"Please wait system busy finding if damage exists?\")\n",
    "    print(pred)\n",
    "    if pred[0][0] <=.5:\n",
    "\n",
    "        print(\"Validation complete - proceed to next\")\n",
    "    else:\n",
    "        print(\"Doesn't seems to be damaged.. please use another picture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "GeqYA9gMXM8j",
    "outputId": "fb32e668-ee55-4f67-cfbf-0e65e3c978f2"
   },
   "outputs": [],
   "source": [
    "car_categories_gate('https://www.copart.co.uk/content/uk/en/landing-page/accident-damaged-classics.jpg',ft_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMAdeAqRbSNI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LEDon494bSL0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sizhso2UbSJA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rLvBO3h8a25x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjJIPvkxreKi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "car_damage_modified_14/02/2019.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
